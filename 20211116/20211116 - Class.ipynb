{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b341a96a-7abb-41dc-aa6f-d972ad95e5d0",
   "metadata": {},
   "source": [
    "# Class content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9da6e7e9-ea5c-4f8a-aefd-0e923fd4d721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: joblib in c:\\tools\\anaconda3\\envs\\college\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\tools\\anaconda3\\envs\\college\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2021.11.10-cp38-cp38-win_amd64.whl (273 kB)\n",
      "Requirement already satisfied: colorama in c:\\tools\\anaconda3\\envs\\college\\lib\\site-packages (from tqdm->nltk) (0.4.4)\n",
      "Installing collected packages: tqdm, regex, nltk\n",
      "Successfully installed nltk-3.6.5 regex-2021.11.10 tqdm-4.62.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595c7379-7978-42be-9544-fc806c62cc91",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Work tokeninzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e075da58-19cd-448f-ba18-8f9dd0bf9661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey',\n",
       " 'everyone!',\n",
       " 'The',\n",
       " 'party',\n",
       " 'starts',\n",
       " 'in',\n",
       " '10mins.',\n",
       " 'Be',\n",
       " 'there',\n",
       " 'ASAP!']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = 'Hey everyone! The party starts in 10mins. Be there ASAP!'\n",
    "msg.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7915f84d-9fea-48c7-b13f-f15e717aba3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey',\n",
       " 'everyone',\n",
       " '!',\n",
       " 'The',\n",
       " 'party',\n",
       " 'starts',\n",
       " 'in',\n",
       " '10mins',\n",
       " '.',\n",
       " 'Be',\n",
       " 'there',\n",
       " 'ASAP',\n",
       " '!']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_word = word_tokenize(msg)\n",
    "tokenized_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87922b01-70de-4936-aaad-b4d2a1c6d864",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3872144-f380-46d8-bb51-81e0c8f7d121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "porter.stem('running')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b18688-010d-46a6-a0ff-cd211e0b45d4",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e4352f-af7b-4404-abf2-3a21210eb8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "print(lem.lemmatize(\"running\", pos = 'n'))\n",
    "print(lem.lemmatize(\"running\", pos = 'v'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70fd2aef-879a-4b58-bea4-d03ada0e618c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "eat\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "print(lem.lemmatize(\"better\", pos = 'a' ) )\n",
    "print(lem.lemmatize(\"ate\", pos = 'v' ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460a9320-5758-4251-b018-f1120bc28b38",
   "metadata": {},
   "source": [
    "## Part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b41c527a-dc13-4439-8886-b324583d682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "text = \"Can you please buy me an Arizona Ice Tea? It is $9.99.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57f95640-ff4d-4c79-81a7-7c2eaeae2833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parts of the speech:  [('Hey', 'NNP'), ('everyone', 'NN'), ('!', '.'), ('The', 'DT'), ('party', 'NN'), ('starts', 'VBZ'), ('in', 'IN'), ('10mins', 'CD'), ('.', '.'), ('Be', 'VB'), ('there', 'EX'), ('ASAP', 'NNP'), ('!', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(msg)\n",
    "print(\"parts of the speech: \" , nltk.pos_tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346407bb-1ea5-4425-a6ba-1ef9e7bb9324",
   "metadata": {},
   "source": [
    "## Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd5d8ae0-b06d-4f17-95f2-3e4a3aebcf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5ac3d1b-71c5-497b-8190-807565117ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = np.array(['I love Brazil. Brazil!',\n",
    "                     'Sweden is best',\n",
    "                     'Germany beats both'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfde9b6a-181b-4001-8ced-28d8fad8f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db02e911-2b92-45ea-8a34-69ca382097b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 2, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 1],\n",
       "       [1, 0, 1, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df7bc470-174f-4cce-9bde-d5b469aa8512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['beats', 'best', 'both', 'brazil', 'germany', 'is', 'love',\n",
       "       'sweden'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8a531c-8468-48a1-8a4a-d198832c53a4",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aec60318-0fd0-4ce4-a9a6-0da2df8f800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "text_data = np.array(['l love Brazil. Brazil! '\n",
    "'Sweden is best' ,\n",
    "'Germany beats both' ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71540904-b589-454d-9441-3b4db4168e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "feature_matrix = tfidf.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0dec356-c52b-4fbb-a244-41022c8890d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.35355339, 0.        , 0.70710678, 0.        ,\n",
       "        0.35355339, 0.35355339, 0.35355339],\n",
       "       [0.57735027, 0.        , 0.57735027, 0.        , 0.57735027,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5bec9bb-512c-4e13-8362-cfb0771585e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 6,\n",
       " 'brazil': 3,\n",
       " 'sweden': 7,\n",
       " 'is': 5,\n",
       " 'best': 1,\n",
       " 'germany': 4,\n",
       " 'beats': 0,\n",
       " 'both': 2}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b5adfd-28bd-43c7-b4b7-f442d9c66f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
